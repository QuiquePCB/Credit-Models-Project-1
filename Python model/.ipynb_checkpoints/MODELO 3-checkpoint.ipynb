{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODELO DE CRÉDITO PARA PRÉSTAMOS PERSONALES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier, XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Función para cargar la información para entrenar y validar el modelo. \n",
    "La información no será proporcionada por el usuario final, sino que ya estará establecida. Se utilizará el archivo \n",
    "con los datos limpios y ordenados que se realizó para el modelo tradicional. \n",
    "\"\"\"\n",
    "def get_data(data):\n",
    "    return pd.read_csv(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Función para separar la data en train y test. \n",
    "Se utilizará el 70% de los datos totales para entrenar el modelo y el 30% restante para verificar su funcionamiento. \n",
    "La división de los datos se realizará de manera aleatoria, establecionedo una semilla para poder replicar los \n",
    "resultados obtenidos. \n",
    "\n",
    "EXPLICAR TARGET COLUMN\n",
    "\"\"\"\n",
    "def split_train_test(data, target_column, random_state=100):\n",
    "    data_train, data_test = train_test_split(\n",
    "        data,\n",
    "        test_size=0.3,\n",
    "        random_state=random_state,\n",
    "        stratify=data[target_column]  \n",
    "    )\n",
    "    return data_train.reset_index(drop=True), data_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Función para preparar los datos. \n",
    "Ya que en los modelos que se utilizarán más adelante los datos deben de estar separados en X y Y, además de estar \n",
    "normalizados (unicamente los valores numéricos), se optó por crear una función que realizara esta preparación. Para utilizarla, es necesario alimentar a esta\n",
    "función con los datos seleccionados para train y para test obtenidos en la función anterior. \n",
    "\"\"\"\n",
    "\n",
    "def prepare_variables(data_train, data_test):\n",
    "    X_train = data_train.drop('Credit_Score', axis=1)\n",
    "    y_train = data_train['Credit_Score']\n",
    "    X_test = data_test.drop('Credit_Score', axis=1)\n",
    "    y_test = data_test['Credit_Score']\n",
    "\n",
    "    numeric_cols = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "    categorical_cols = X_train.select_dtypes(exclude=['int64', 'float64']).columns\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = X_train.copy()\n",
    "    X_test_scaled = X_test.copy()\n",
    "    \n",
    "    X_train_scaled[numeric_cols] = scaler.fit_transform(X_train[numeric_cols])\n",
    "    X_test_scaled[numeric_cols] = scaler.transform(X_test[numeric_cols])\n",
    "\n",
    "    return X_train_scaled, X_test_scaled, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Función para crear un primer modelo con el método de Random Forest. \n",
    "Esta función entrará con los datos normalizados para poder proponer una predicción y una probabilidad asociada. \n",
    "\n",
    "EXPLICAR UN POCO MÁS QUE ES RF\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#RF FALTA DOCUMENTACION Y CAMBIAR COLUMNA\n",
    "def random_forest(X_train_scaled,X_test_scaled, y_train):\n",
    "    rf_model = RandomForestClassifier(random_state=100)\n",
    "    rf_model.fit(X_train_scaled, y_train)\n",
    "    rf_probs = rf_model.predict_proba(X_test_scaled)[:, 1]\n",
    "    rf_preds = rf_model.predict(X_test_scaled)\n",
    "    \n",
    "    return rf_probs,rf_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(X_train_scaled, y_train):\n",
    "    lr_model = LogisticRegression(max_iter=1000, random_state=100)\n",
    "    lr_model.fit(X_train_scaled, y_train)\n",
    "    lr_probs = lr_model.predict_proba(X_test_scaled)[:, 1]\n",
    "    lr_preds = lr_model.predict(X_test_scaled)\n",
    "    \n",
    "    return lr_probs,lr_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el modelo CatBoost\n",
    "def catboost_model(X_train_scaled, y_train_scaled, cat_features=None, iterations=1000, learning_rate=0.03, depth=6):\n",
    "    model = CatBoostClassifier(\n",
    "        iterations=iterations,\n",
    "        learning_rate=learning_rate,\n",
    "        depth=depth,\n",
    "        cat_features=cat_features,\n",
    "        verbose=0 \n",
    "    )\n",
    "    \n",
    "    return model.fit(X_train_scaled, y_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgboost_model(X_train_scaled, y_train_scaled, task_type='classification', **params):\n",
    "   \n",
    "    if task_type == 'classification':\n",
    "        model = XGBClassifier(**params)\n",
    "    else:\n",
    "        model = XGBRegressor(**params)\n",
    "    \n",
    "    return model.fit(X_train_scaled, y_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_roc_metrics(y_test, probs):\n",
    "    fpr, tpr, _ = roc_curve(y_test, probs)\n",
    "    auc = roc_auc_score(y_test, probs)\n",
    "    return fpr, tpr, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFunción para cargar la info del modelo\\nSeparar en trian y test \\nFunción para entrenador el modelo con RF\\nFunción para entrenador el modelo con Regresion \\nFunción para entrenador el modelo con ---\\nfUNCION PARA COMBINARLOS\\nFunción para evaluar los modelos \\nFuincion Auroc\\nFuncion matriz\\nFunción para que el usuario inserte el cliente a evaluar\\n¿Qué hacer en caso de que no se tenga un dato?\\n'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Función para cargar la info del modelo\n",
    "Separar en trian y test \n",
    "Función para entrenador el modelo con RF\n",
    "Función para entrenador el modelo con Regresion \n",
    "Función para entrenador el modelo con ---\n",
    "fUNCION PARA COMBINARLOS\n",
    "Función para evaluar los modelos \n",
    "Fuincion Auroc\n",
    "Funcion matriz\n",
    "Función para que el usuario inserte el cliente a evaluar\n",
    "¿Qué hacer en caso de que no se tenga un dato?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Función para cargar y leer los datos con la información crediticia que se utilizará para entrenar y validar el modelo.\n",
    "\n",
    "El archivo que contenga estos datos debe de ser presentado en formato csv, de lo contrario, un mensaje de error hará saber\n",
    "al usuario que el archivo no cumple con el formato solicitado.\n",
    "El archivo debe de contener las siguientes 12 columnas en el orden que a continuación se presenta, cuidando\n",
    "que estas correspondan a las primeras 12 columnas del documento: Interest_Rate, Delay_from_due_date,\n",
    "Payment_of_Min_Amount, Outstanding_Debt, Num_Credit_Inquiries, Num_of_Delayed_Payment, Num_of_Loan, \n",
    "Credit_Utilization_Ratio, Num_Bank_Accounts, Num_Credit_Card, Credit_Mix, Credit_History_Age. \n",
    "\n",
    "Clasifiación para las variables que no son numéricas:\n",
    "•Payment_of_Min_Amount: Yes, No, NM (Not Mentioned)\n",
    "•Credit_Mix: Good, Standard, Poor\n",
    "\n",
    "También es importante mencionar que el Interest_Rate se debe indicar como números enteros, no como porcentaje.\n",
    "Para Outstanding_Debt, Credit_Utilization_Ratio y Credit_History_Age se pueden usar puntos decimales y para las \n",
    "restantes son números enteros.\n",
    "El Delay_from_due_date debe indicarse en número de días.\n",
    "\n",
    "En caso de tener valores faltantes se pondra cero para el caso de las columnas numéricas y NA para las categóricas. \n",
    "\"\"\"\n",
    "def insert_credit_info(info):\n",
    "    if not info.lower().endswith('.csv'):\n",
    "        raise ValueError(\"El formato del archivo proporcionado no concuerda con el solicitado.\")\n",
    "    \n",
    "    return pd.read_csv(info)\n",
    "\n",
    "#Evaluar el modelo en lso datos porporcionado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"data_train_cleaned_final.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = get_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_train, data_test = split_train_test(data,target_column=\"Credit_Score\", random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PAVILION\\anaconda\\lib\\site-packages\\sklearn\\utils\\extmath.py:985: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "C:\\Users\\PAVILION\\anaconda\\lib\\site-packages\\sklearn\\utils\\extmath.py:990: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "C:\\Users\\PAVILION\\anaconda\\lib\\site-packages\\sklearn\\utils\\extmath.py:1020: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction ** 2 / new_sample_count\n"
     ]
    }
   ],
   "source": [
    "X_train_scaled,X_test_scaled, y_train, y_test= prepare_variables(data_train,data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
